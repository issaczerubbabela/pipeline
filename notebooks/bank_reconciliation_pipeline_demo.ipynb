{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9139803c",
   "metadata": {},
   "source": [
    "# Bank Reconciliation Pipeline with PySpark and Data Lineage\n",
    "\n",
    "This comprehensive notebook demonstrates a complete data pipeline for bank reconciliation using PySpark, featuring:\n",
    "\n",
    "- üìÅ **Interactive File Upload** - Upload CSV/Excel files with drag-and-drop interface\n",
    "- ‚úÖ **Dynamic Validation Rules** - Create custom validation rules for data quality\n",
    "- üîÑ **Data Reconciliation** - Compare datasets and identify discrepancies  \n",
    "- üîó **Data Lineage Tracking** - Complete audit trail of data transformations\n",
    "- üìä **Real-time Monitoring** - Live dashboards for pipeline status and logs\n",
    "- üöÄ **End-to-end Pipeline** - Raw data to reportable format transformation\n",
    "\n",
    "## Prerequisites\n",
    "- PySpark installed and configured\n",
    "- Java 8+ for Spark\n",
    "- Required Python packages: pandas, ipywidgets, plotly\n",
    "\n",
    "Let's start by importing libraries and setting up our environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec61a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries and Initialize Spark\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to path for imports\n",
    "notebook_dir = Path.cwd()\n",
    "src_path = notebook_dir.parent / \"src\"\n",
    "sys.path.append(str(src_path))\n",
    "\n",
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import uuid\n",
    "import logging\n",
    "\n",
    "# PySpark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Visualization libraries\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Interactive widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üöÄ Initializing Spark session...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8249450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark Session with Optimized Configuration\n",
    "def create_spark_session():\n",
    "    try:\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"BankReconciliationPipeline\") \\\n",
    "            .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "            .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "            .config(\"spark.driver.memory\", \"2g\") \\\n",
    "            .config(\"spark.executor.memory\", \"2g\") \\\n",
    "            .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "            .getOrCreate()\n",
    "        \n",
    "        spark.sparkContext.setLogLevel(\"WARN\")  # Reduce log verbosity\n",
    "        return spark\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to initialize Spark: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create Spark session\n",
    "spark = create_spark_session()\n",
    "\n",
    "if spark:\n",
    "    print(\"‚úÖ Spark session initialized successfully!\")\n",
    "    print(f\"üî• Spark version: {spark.version}\")\n",
    "    print(f\"üíæ Available cores: {spark.sparkContext.defaultParallelism}\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to initialize Spark session. Please check your configuration.\")\n",
    "\n",
    "# Global variables for pipeline state\n",
    "uploaded_files = {}\n",
    "validation_rules = {}\n",
    "reconciliation_config = {}\n",
    "lineage_events = []\n",
    "pipeline_logs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c482b3e9",
   "metadata": {},
   "source": [
    "## üìÅ File Upload Widget Implementation\n",
    "\n",
    "Interactive file upload interface for CSV and Excel files with automatic schema detection and preview capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Upload Widget Implementation\n",
    "class FileUploadManager:\n",
    "    def __init__(self, spark_session):\n",
    "        self.spark = spark_session\n",
    "        self.uploaded_data = {}\n",
    "        \n",
    "    def create_upload_widget(self, dataset_name):\n",
    "        \"\"\"Create file upload widget for a dataset\"\"\"\n",
    "        upload_widget = widgets.FileUpload(\n",
    "            accept='.csv,.xlsx,.xls',\n",
    "            multiple=False,\n",
    "            description=f'Upload {dataset_name}',\n",
    "            style={'button_color': '#4CAF50'}\n",
    "        )\n",
    "        \n",
    "        output_widget = widgets.Output()\n",
    "        \n",
    "        def on_upload_change(change):\n",
    "            with output_widget:\n",
    "                clear_output()\n",
    "                if upload_widget.value:\n",
    "                    file_info = list(upload_widget.value.values())[0]\n",
    "                    filename = list(upload_widget.value.keys())[0]\n",
    "                    \n",
    "                    print(f\"üìÅ Processing file: {filename}\")\n",
    "                    print(f\"üìä File size: {len(file_info['content']) / 1024:.1f} KB\")\n",
    "                    \n",
    "                    try:\n",
    "                        # Save file temporarily\n",
    "                        temp_path = f\"temp_{dataset_name}_{filename}\"\n",
    "                        with open(temp_path, \"wb\") as f:\n",
    "                            f.write(file_info['content'])\n",
    "                        \n",
    "                        # Load data into Spark DataFrame\n",
    "                        df = self.load_file_to_dataframe(temp_path, filename)\n",
    "                        \n",
    "                        if df is not None:\n",
    "                            self.uploaded_data[dataset_name] = {\n",
    "                                'dataframe': df,\n",
    "                                'filename': filename,\n",
    "                                'temp_path': temp_path,\n",
    "                                'row_count': df.count(),\n",
    "                                'column_count': len(df.columns),\n",
    "                                'columns': df.columns,\n",
    "                                'schema': df.dtypes\n",
    "                            }\n",
    "                            \n",
    "                            # Track in lineage\n",
    "                            event_id = self.track_source_event(dataset_name, filename, df)\n",
    "                            self.uploaded_data[dataset_name]['event_id'] = event_id\n",
    "                            \n",
    "                            print(f\"‚úÖ Successfully loaded {df.count()} rows, {len(df.columns)} columns\")\n",
    "                            \n",
    "                            # Display preview\n",
    "                            self.display_data_preview(dataset_name)\n",
    "                            \n",
    "                        else:\n",
    "                            print(\"‚ùå Failed to load file\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Error processing file: {str(e)}\")\n",
    "        \n",
    "        upload_widget.observe(on_upload_change, names='value')\n",
    "        \n",
    "        return widgets.VBox([\n",
    "            widgets.HTML(f\"<h4>üìÅ {dataset_name} Upload</h4>\"),\n",
    "            upload_widget,\n",
    "            output_widget\n",
    "        ])\n",
    "    \n",
    "    def load_file_to_dataframe(self, file_path, filename):\n",
    "        \"\"\"Load file into Spark DataFrame\"\"\"\n",
    "        try:\n",
    "            if filename.endswith('.csv'):\n",
    "                df = self.spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(file_path)\n",
    "            elif filename.endswith(('.xlsx', '.xls')):\n",
    "                # Use pandas for Excel, then convert to Spark\n",
    "                pandas_df = pd.read_excel(file_path)\n",
    "                df = self.spark.createDataFrame(pandas_df)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported file format: {filename}\")\n",
    "            \n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def track_source_event(self, dataset_name, filename, df):\n",
    "        \"\"\"Track data source in lineage\"\"\"\n",
    "        event_id = str(uuid.uuid4())\n",
    "        event = {\n",
    "            'event_id': event_id,\n",
    "            'event_type': 'SOURCE',\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'dataset_name': dataset_name,\n",
    "            'filename': filename,\n",
    "            'row_count': df.count(),\n",
    "            'column_count': len(df.columns),\n",
    "            'columns': df.columns,\n",
    "            'schema': df.dtypes\n",
    "        }\n",
    "        lineage_events.append(event)\n",
    "        pipeline_logs.append(f\"[{datetime.now().strftime('%H:%M:%S')}] SOURCE: Loaded {dataset_name} from {filename}\")\n",
    "        return event_id\n",
    "    \n",
    "    def display_data_preview(self, dataset_name):\n",
    "        \"\"\"Display data preview and schema information\"\"\"\n",
    "        if dataset_name not in self.uploaded_data:\n",
    "            return\n",
    "        \n",
    "        data_info = self.uploaded_data[dataset_name]\n",
    "        df = data_info['dataframe']\n",
    "        \n",
    "        print(\"\\\\nüìä Data Preview:\")\n",
    "        preview_df = df.limit(5).toPandas()\n",
    "        display(preview_df)\n",
    "        \n",
    "        print(\"\\\\nüìã Column Information:\")\n",
    "        schema_df = pd.DataFrame(data_info['schema'], columns=['Column', 'Type'])\n",
    "        display(schema_df)\n",
    "\n",
    "# Create file upload manager\n",
    "upload_manager = FileUploadManager(spark)\n",
    "\n",
    "# Create upload widgets for two datasets\n",
    "dataset1_upload = upload_manager.create_upload_widget(\"Dataset 1 (Bank Statement)\")\n",
    "dataset2_upload = upload_manager.create_upload_widget(\"Dataset 2 (General Ledger)\")\n",
    "\n",
    "# Display upload widgets\n",
    "display(widgets.HBox([dataset1_upload, dataset2_upload]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a8a585",
   "metadata": {},
   "source": [
    "## üîç Data Schema Detection and Column Selection\n",
    "\n",
    "Automatically detect data schemas and provide interactive column selection for validation and reconciliation operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9dfd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Schema Detection and Column Selection\n",
    "class SchemaManager:\n",
    "    def __init__(self, upload_manager):\n",
    "        self.upload_manager = upload_manager\n",
    "        self.column_mappings = {}\n",
    "        \n",
    "    def create_schema_analysis_widget(self):\n",
    "        \"\"\"Create widget for schema analysis and column selection\"\"\"\n",
    "        output_widget = widgets.Output()\n",
    "        refresh_button = widgets.Button(\n",
    "            description=\"üîÑ Analyze Schemas\",\n",
    "            button_style='info',\n",
    "            style={'button_color': '#2196F3'}\n",
    "        )\n",
    "        \n",
    "        def analyze_schemas(button):\n",
    "            with output_widget:\n",
    "                clear_output()\n",
    "                \n",
    "                if not self.upload_manager.uploaded_data:\n",
    "                    print(\"‚ö†Ô∏è Please upload datasets first!\")\n",
    "                    return\n",
    "                \n",
    "                print(\"üîç Analyzing schemas...\")\n",
    "                \n",
    "                for dataset_name, data_info in self.upload_manager.uploaded_data.items():\n",
    "                    print(f\"\\\\nüìä {dataset_name}:\")\n",
    "                    print(f\"   Rows: {data_info['row_count']:,}\")\n",
    "                    print(f\"   Columns: {data_info['column_count']}\")\n",
    "                    \n",
    "                    # Detailed schema analysis\n",
    "                    df = data_info['dataframe']\n",
    "                    \n",
    "                    # Check for null values\n",
    "                    null_counts = []\n",
    "                    for col_name in df.columns:\n",
    "                        null_count = df.filter(col(col_name).isNull()).count()\n",
    "                        null_counts.append((col_name, null_count))\n",
    "                    \n",
    "                    # Create schema summary\n",
    "                    schema_summary = []\n",
    "                    for i, (col_name, col_type) in enumerate(data_info['schema']):\n",
    "                        null_count = null_counts[i][1]\n",
    "                        null_percentage = (null_count / data_info['row_count']) * 100\n",
    "                        \n",
    "                        schema_summary.append({\n",
    "                            'Column': col_name,\n",
    "                            'Type': col_type,\n",
    "                            'Null Count': null_count,\n",
    "                            'Null %': f\"{null_percentage:.1f}%\"\n",
    "                        })\n",
    "                    \n",
    "                    schema_df = pd.DataFrame(schema_summary)\n",
    "                    display(schema_df)\n",
    "                    \n",
    "                    # Sample values for each column\n",
    "                    print(f\"\\\\nüìã Sample values for {dataset_name}:\")\n",
    "                    sample_data = df.limit(3).toPandas()\n",
    "                    for col_name in sample_data.columns:\n",
    "                        values = sample_data[col_name].tolist()\n",
    "                        print(f\"   {col_name}: {values}\")\n",
    "                \n",
    "                # Create column mapping interface\n",
    "                self.create_column_mapping_interface(output_widget)\n",
    "        \n",
    "        refresh_button.on_click(analyze_schemas)\n",
    "        \n",
    "        return widgets.VBox([\n",
    "            widgets.HTML(\"<h4>üîç Schema Analysis</h4>\"),\n",
    "            refresh_button,\n",
    "            output_widget\n",
    "        ])\n",
    "    \n",
    "    def create_column_mapping_interface(self, output_widget):\n",
    "        \"\"\"Create interface for column mapping and selection\"\"\"\n",
    "        if len(self.upload_manager.uploaded_data) < 2:\n",
    "            return\n",
    "        \n",
    "        datasets = list(self.upload_manager.uploaded_data.keys())\n",
    "        dataset1_cols = self.upload_manager.uploaded_data[datasets[0]]['columns']\n",
    "        dataset2_cols = self.upload_manager.uploaded_data[datasets[1]]['columns']\n",
    "        \n",
    "        with output_widget:\n",
    "            print(\"\\\\nüîó Column Mapping for Reconciliation:\")\n",
    "            print(\"Select columns that should be matched between datasets\")\n",
    "            \n",
    "            # Find potential matches\n",
    "            common_cols = set(dataset1_cols).intersection(set(dataset2_cols))\n",
    "            \n",
    "            if common_cols:\n",
    "                print(f\"\\\\n‚úÖ Common columns found: {list(common_cols)}\")\n",
    "                \n",
    "                # Create mapping widgets\n",
    "                mapping_widgets = []\n",
    "                for common_col in common_cols:\n",
    "                    checkbox = widgets.Checkbox(\n",
    "                        value=True,\n",
    "                        description=f\"Map: {common_col}\",\n",
    "                        disabled=False\n",
    "                    )\n",
    "                    mapping_widgets.append(checkbox)\n",
    "                \n",
    "                # Join key selection\n",
    "                join_keys_widget = widgets.SelectMultiple(\n",
    "                    options=list(common_cols),\n",
    "                    value=list(common_cols)[:1] if common_cols else [],\n",
    "                    description='Join Keys:',\n",
    "                    disabled=False\n",
    "                )\n",
    "                \n",
    "                # Compare columns selection\n",
    "                compare_cols_widget = widgets.SelectMultiple(\n",
    "                    options=list(common_cols),\n",
    "                    value=list(common_cols)[1:] if len(common_cols) > 1 else [],\n",
    "                    description='Compare Columns:',\n",
    "                    disabled=False\n",
    "                )\n",
    "                \n",
    "                # Store selections\n",
    "                def save_mapping(button):\n",
    "                    self.column_mappings = {\n",
    "                        'join_keys': list(join_keys_widget.value),\n",
    "                        'compare_columns': list(compare_cols_widget.value),\n",
    "                        'common_columns': list(common_cols)\n",
    "                    }\n",
    "                    print(\"\\\\n‚úÖ Column mapping saved!\")\n",
    "                \n",
    "                save_button = widgets.Button(\n",
    "                    description=\"üíæ Save Mapping\",\n",
    "                    button_style='success'\n",
    "                )\n",
    "                save_button.on_click(save_mapping)\n",
    "                \n",
    "                display(widgets.VBox([\n",
    "                    widgets.HTML(\"<h5>üîó Reconciliation Configuration</h5>\"),\n",
    "                    join_keys_widget,\n",
    "                    compare_cols_widget,\n",
    "                    save_button\n",
    "                ]))\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è No common columns found between datasets\")\n",
    "\n",
    "# Create schema manager and display widget\n",
    "schema_manager = SchemaManager(upload_manager)\n",
    "schema_widget = schema_manager.create_schema_analysis_widget()\n",
    "display(schema_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73129a8",
   "metadata": {},
   "source": [
    "## ‚úÖ Rule Creation Interface\n",
    "\n",
    "Interactive interface for creating data validation and business rules with support for multiple rule types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c06c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule Creation Interface\n",
    "class RuleManager:\n",
    "    def __init__(self, upload_manager):\n",
    "        self.upload_manager = upload_manager\n",
    "        self.rules = {}\n",
    "        \n",
    "    def create_rule_builder_widget(self):\n",
    "        \"\"\"Create comprehensive rule builder interface\"\"\"\n",
    "        \n",
    "        # Main container\n",
    "        rule_container = widgets.VBox()\n",
    "        \n",
    "        # Dataset selection\n",
    "        dataset_selector = widgets.Dropdown(\n",
    "            options=[],\n",
    "            description='Dataset:',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        # Column selection\n",
    "        column_selector = widgets.Dropdown(\n",
    "            options=[],\n",
    "            description='Column:',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        # Rule type selection\n",
    "        rule_type_selector = widgets.Dropdown(\n",
    "            options=[\n",
    "                ('Not Null', 'not_null'),\n",
    "                ('Unique Values', 'unique'),\n",
    "                ('Numeric Range', 'range'),\n",
    "                ('String Format (Regex)', 'format'),\n",
    "                ('Custom SQL Condition', 'custom')\n",
    "            ],\n",
    "            description='Rule Type:',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        # Rule name\n",
    "        rule_name_input = widgets.Text(\n",
    "            description='Rule Name:',\n",
    "            placeholder='Enter rule name...'\n",
    "        )\n",
    "        \n",
    "        # Dynamic rule parameters container\n",
    "        rule_params_container = widgets.VBox()\n",
    "        \n",
    "        # Rule list display\n",
    "        rules_display = widgets.Output()\n",
    "        \n",
    "        # Buttons\n",
    "        add_rule_button = widgets.Button(\n",
    "            description=\"‚ûï Add Rule\",\n",
    "            button_style='primary',\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        clear_rules_button = widgets.Button(\n",
    "            description=\"üóëÔ∏è Clear All\",\n",
    "            button_style='warning'\n",
    "        )\n",
    "        \n",
    "        test_rules_button = widgets.Button(\n",
    "            description=\"üß™ Test Rules\",\n",
    "            button_style='info'\n",
    "        )\n",
    "        \n",
    "        # Update dataset options when data is uploaded\n",
    "        def update_dataset_options():\n",
    "            if self.upload_manager.uploaded_data:\n",
    "                dataset_selector.options = list(self.upload_manager.uploaded_data.keys())\n",
    "                dataset_selector.disabled = False\n",
    "            else:\n",
    "                dataset_selector.options = []\n",
    "                dataset_selector.disabled = True\n",
    "        \n",
    "        # Update column options when dataset is selected\n",
    "        def on_dataset_change(change):\n",
    "            if change['new'] in self.upload_manager.uploaded_data:\n",
    "                columns = self.upload_manager.uploaded_data[change['new']]['columns']\n",
    "                column_selector.options = columns\n",
    "                column_selector.disabled = False\n",
    "                rule_type_selector.disabled = False\n",
    "                add_rule_button.disabled = False\n",
    "            else:\n",
    "                column_selector.options = []\n",
    "                column_selector.disabled = True\n",
    "                rule_type_selector.disabled = True\n",
    "                add_rule_button.disabled = True\n",
    "        \n",
    "        dataset_selector.observe(on_dataset_change, names='value')\n",
    "        \n",
    "        # Update rule parameters based on rule type\n",
    "        def on_rule_type_change(change):\n",
    "            rule_params_container.children = self.create_rule_parameters(change['new'])\\n        \\n        rule_type_selector.observe(on_rule_type_change, names='value')\n",
    "        \n",
    "        # Add rule function\n",
    "        def add_rule(button):\n",
    "            dataset = dataset_selector.value\n",
    "            column = column_selector.value\n",
    "            rule_type = rule_type_selector.value\n",
    "            rule_name = rule_name_input.value or f\"{rule_type}_{column}\"\n",
    "            \n",
    "            if not all([dataset, column, rule_type]):\n",
    "                with rules_display:\n",
    "                    print(\"‚ö†Ô∏è Please fill all required fields\")\n",
    "                return\n",
    "            \n",
    "            # Collect rule parameters\n",
    "            rule_params = self.collect_rule_parameters(rule_params_container.children)\n",
    "            \n",
    "            # Create rule object\n",
    "            rule = {\n",
    "                'name': rule_name,\n",
    "                'dataset': dataset,\n",
    "                'column': column,\n",
    "                'type': rule_type,\n",
    "                **rule_params\n",
    "            }\n",
    "            \n",
    "            # Add to rules dictionary\n",
    "            if dataset not in self.rules:\n",
    "                self.rules[dataset] = []\n",
    "            \n",
    "            self.rules[dataset].append(rule)\n",
    "            \n",
    "            # Update display\n",
    "            self.update_rules_display(rules_display)\n",
    "            \n",
    "            # Clear form\n",
    "            rule_name_input.value = \"\"\n",
    "            \n",
    "            # Track in lineage\n",
    "            event_id = str(uuid.uuid4())\n",
    "            lineage_events.append({\n",
    "                'event_id': event_id,\n",
    "                'event_type': 'RULE_CREATION',\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'rule': rule\n",
    "            })\n",
    "            pipeline_logs.append(f\"[{datetime.now().strftime('%H:%M:%S')}] RULE: Created {rule_name} for {dataset}.{column}\")\n",
    "        \n",
    "        add_rule_button.on_click(add_rule)\n",
    "        \n",
    "        # Clear rules function\n",
    "        def clear_rules(button):\n",
    "            self.rules = {}\n",
    "            self.update_rules_display(rules_display)\n",
    "            pipeline_logs.append(f\"[{datetime.now().strftime('%H:%M:%S')}] RULE: Cleared all rules\")\n",
    "        \n",
    "        clear_rules_button.on_click(clear_rules)\n",
    "        \n",
    "        # Test rules function\n",
    "        def test_rules(button):\n",
    "            self.test_validation_rules(rules_display)\n",
    "        \n",
    "        test_rules_button.on_click(test_rules)\n",
    "        \n",
    "        # Refresh button to update dataset options\n",
    "        refresh_button = widgets.Button(\n",
    "            description=\"üîÑ Refresh\",\n",
    "            button_style='info'\n",
    "        )\n",
    "        \n",
    "        def refresh_datasets(button):\n",
    "            update_dataset_options()\n",
    "        \n",
    "        refresh_button.on_click(refresh_datasets)\n",
    "        \n",
    "        # Initial update\n",
    "        update_dataset_options()\n",
    "        \n",
    "        # Assemble widget\n",
    "        rule_container.children = [\n",
    "            widgets.HTML(\"<h4>‚úÖ Validation Rule Builder</h4>\"),\n",
    "            widgets.HBox([dataset_selector, refresh_button]),\n",
    "            column_selector,\n",
    "            rule_type_selector,\n",
    "            rule_name_input,\n",
    "            rule_params_container,\n",
    "            widgets.HBox([add_rule_button, clear_rules_button, test_rules_button]),\n",
    "            widgets.HTML(\"<h5>üìã Current Rules</h5>\"),\n",
    "            rules_display\n",
    "        ]\n",
    "        \n",
    "        return rule_container\n",
    "    \n",
    "    def create_rule_parameters(self, rule_type):\n",
    "        \"\"\"Create parameter widgets based on rule type\"\"\"\n",
    "        if rule_type == 'range':\n",
    "            return [\n",
    "                widgets.FloatText(description='Min Value:', value=0.0),\n",
    "                widgets.FloatText(description='Max Value:', value=100.0)\n",
    "            ]\n",
    "        elif rule_type == 'format':\n",
    "            return [\n",
    "                widgets.Text(\n",
    "                    description='Regex Pattern:',\n",
    "                    placeholder='e.g., ^[A-Z]{2}[0-9]{4}$',\n",
    "                    value=''\n",
    "                )\n",
    "            ]\n",
    "        elif rule_type == 'custom':\n",
    "            return [\n",
    "                widgets.Textarea(\n",
    "                    description='SQL Condition:',\n",
    "                    placeholder='e.g., column_name > 0 AND column_name < 1000',\n",
    "                    value=''\n",
    "                )\n",
    "            ]\n",
    "        else:\n",
    "            return [widgets.HTML(\"<i>No additional parameters required</i>\")]\n",
    "    \n",
    "    def collect_rule_parameters(self, param_widgets):\n",
    "        \"\"\"Collect parameters from parameter widgets\"\"\"\n",
    "        params = {}\n",
    "        for widget in param_widgets:\n",
    "            if hasattr(widget, 'description') and hasattr(widget, 'value'):\n",
    "                if 'Min Value' in widget.description:\n",
    "                    params['min_value'] = widget.value\n",
    "                elif 'Max Value' in widget.description:\n",
    "                    params['max_value'] = widget.value\n",
    "                elif 'Regex Pattern' in widget.description:\n",
    "                    params['pattern'] = widget.value\n",
    "                elif 'SQL Condition' in widget.description:\n",
    "                    params['condition'] = widget.value\n",
    "        return params\n",
    "    \n",
    "    def update_rules_display(self, output_widget):\n",
    "        \"\"\"Update the rules display\"\"\"\n",
    "        with output_widget:\n",
    "            clear_output()\n",
    "            if not self.rules:\n",
    "                print(\"üìã No rules defined yet\")\n",
    "                return\n",
    "            \n",
    "            for dataset, rules_list in self.rules.items():\n",
    "                print(f\"\\\\nüìä {dataset} ({len(rules_list)} rules):\")\n",
    "                for i, rule in enumerate(rules_list, 1):\n",
    "                    rule_desc = f\"{i}. {rule['name']} ({rule['type']}) on {rule['column']}\"\n",
    "                    if rule['type'] == 'range':\n",
    "                        rule_desc += f\" [{rule.get('min_value', 'N/A')} - {rule.get('max_value', 'N/A')}]\"\n",
    "                    elif rule['type'] == 'format':\n",
    "                        rule_desc += f\" pattern: {rule.get('pattern', 'N/A')}\"\n",
    "                    print(f\"   {rule_desc}\")\n",
    "    \n",
    "    def test_validation_rules(self, output_widget):\n",
    "        \"\"\"Test validation rules on uploaded data\"\"\"\n",
    "        if not self.rules:\n",
    "            with output_widget:\n",
    "                print(\"‚ö†Ô∏è No rules to test\")\n",
    "            return\n",
    "        \n",
    "        with output_widget:\n",
    "            print(\"\\\\nüß™ Testing validation rules...\")\n",
    "            \n",
    "            for dataset, rules_list in self.rules.items():\n",
    "                if dataset in self.upload_manager.uploaded_data:\n",
    "                    df = self.upload_manager.uploaded_data[dataset]['dataframe']\n",
    "                    print(f\"\\\\nüìä Testing {len(rules_list)} rules on {dataset}:\")\n",
    "                    \n",
    "                    for rule in rules_list:\n",
    "                        result = self.apply_validation_rule(df, rule)\n",
    "                        status = \"‚úÖ PASS\" if result['passed'] else \"‚ùå FAIL\"\n",
    "                        print(f\"   {rule['name']}: {status} ({result['violations']} violations)\")\n",
    "\n",
    "    def apply_validation_rule(self, df, rule):\n",
    "        \"\"\"Apply a single validation rule\"\"\"\n",
    "        column = rule['column']\n",
    "        rule_type = rule['type']\n",
    "        \n",
    "        try:\n",
    "            if rule_type == 'not_null':\n",
    "                violations = df.filter(col(column).isNull()).count()\n",
    "            elif rule_type == 'unique':\n",
    "                total_rows = df.count()\n",
    "                unique_rows = df.select(column).distinct().count()\n",
    "                violations = total_rows - unique_rows\n",
    "            elif rule_type == 'range':\n",
    "                min_val = rule.get('min_value', float('-inf'))\n",
    "                max_val = rule.get('max_value', float('inf'))\n",
    "                violations = df.filter(\n",
    "                    (col(column) < min_val) | (col(column) > max_val)\n",
    "                ).count()\n",
    "            elif rule_type == 'format':\n",
    "                pattern = rule.get('pattern', '')\n",
    "                violations = df.filter(~col(column).rlike(pattern)).count()\n",
    "            elif rule_type == 'custom':\n",
    "                condition = rule.get('condition', '')\n",
    "                violations = df.filter(~expr(condition.replace('column_name', column))).count()\n",
    "            else:\n",
    "                violations = 0\n",
    "            \n",
    "            return {\n",
    "                'passed': violations == 0,\n",
    "                'violations': violations,\n",
    "                'error': None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'passed': False,\n",
    "                'violations': 0,\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "# Create rule manager and display widget\n",
    "rule_manager = RuleManager(upload_manager)\n",
    "rule_builder_widget = rule_manager.create_rule_builder_widget()\n",
    "display(rule_builder_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950308f8",
   "metadata": {},
   "source": [
    "## üîç Data Validation Engine\n",
    "\n",
    "Comprehensive validation engine that applies rules to data and generates detailed validation reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34985d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Validation Engine\n",
    "class ValidationEngine:\n",
    "    def __init__(self, spark_session, rule_manager, upload_manager):\n",
    "        self.spark = spark_session\n",
    "        self.rule_manager = rule_manager\n",
    "        self.upload_manager = upload_manager\n",
    "        self.validation_results = {}\n",
    "        \n",
    "    def create_validation_widget(self):\n",
    "        \"\"\"Create validation execution and results widget\"\"\"\n",
    "        \n",
    "        output_widget = widgets.Output()\n",
    "        \n",
    "        # Validation control buttons\n",
    "        run_validation_button = widgets.Button(\n",
    "            description=\"üöÄ Run Validation\",\n",
    "            button_style='success',\n",
    "            style={'button_color': '#4CAF50'}\n",
    "        )\n",
    "        \n",
    "        export_results_button = widgets.Button(\n",
    "            description=\"üìä Export Results\",\n",
    "            button_style='info'\n",
    "        )\n",
    "        \n",
    "        def run_validation(button):\n",
    "            with output_widget:\n",
    "                clear_output()\n",
    "                if not self.rule_manager.rules:\n",
    "                    print(\"‚ö†Ô∏è No validation rules defined!\")\n",
    "                    return\n",
    "                \n",
    "                print(\"üöÄ Starting validation process...\")\n",
    "                self.validation_results = {}\n",
    "                \n",
    "                for dataset_name, rules_list in self.rule_manager.rules.items():\n",
    "                    if dataset_name in self.upload_manager.uploaded_data:\n",
    "                        print(f\"\\\\nüìä Validating {dataset_name}...\")\n",
    "                        \n",
    "                        df = self.upload_manager.uploaded_data[dataset_name]['dataframe']\n",
    "                        dataset_results = self.validate_dataset(df, rules_list, dataset_name)\n",
    "                        self.validation_results[dataset_name] = dataset_results\n",
    "                        \n",
    "                        # Display results summary\n",
    "                        self.display_validation_summary(dataset_name, dataset_results)\n",
    "                \n",
    "                # Create detailed validation report\n",
    "                print(\"\\\\nüìã Generating detailed validation report...\")\n",
    "                self.create_validation_report()\n",
    "        \n",
    "        run_validation_button.on_click(run_validation)\n",
    "        \n",
    "        def export_results(button):\n",
    "            with output_widget:\n",
    "                if not self.validation_results:\n",
    "                    print(\"‚ö†Ô∏è No validation results to export!\")\n",
    "                    return\n",
    "                \n",
    "                self.export_validation_results()\n",
    "                print(\"‚úÖ Validation results exported!\")\n",
    "        \n",
    "        export_results_button.on_click(export_results)\n",
    "        \n",
    "        return widgets.VBox([\n",
    "            widgets.HTML(\"<h4>üîç Data Validation Engine</h4>\"),\n",
    "            widgets.HBox([run_validation_button, export_results_button]),\n",
    "            output_widget\n",
    "        ])\n",
    "    \n",
    "    def validate_dataset(self, df, rules_list, dataset_name):\n",
    "        \"\"\"Validate a dataset against a list of rules\"\"\"\n",
    "        results = {\n",
    "            'dataset_name': dataset_name,\n",
    "            'total_rows': df.count(),\n",
    "            'rules_applied': len(rules_list),\n",
    "            'rules_passed': 0,\n",
    "            'rules_failed': 0,\n",
    "            'total_violations': 0,\n",
    "            'rule_results': []\n",
    "        }\n",
    "        \n",
    "        for rule in rules_list:\n",
    "            rule_result = self.rule_manager.apply_validation_rule(df, rule)\n",
    "            \n",
    "            # Enhance rule result with additional information\n",
    "            enhanced_result = {\n",
    "                **rule_result,\n",
    "                'rule_name': rule['name'],\n",
    "                'rule_type': rule['type'],\n",
    "                'column': rule['column'],\n",
    "                'dataset': dataset_name,\n",
    "                'violation_percentage': (rule_result['violations'] / results['total_rows']) * 100 if results['total_rows'] > 0 else 0\n",
    "            }\n",
    "            \n",
    "            results['rule_results'].append(enhanced_result)\n",
    "            \n",
    "            if rule_result['passed']:\n",
    "                results['rules_passed'] += 1\n",
    "            else:\n",
    "                results['rules_failed'] += 1\n",
    "                results['total_violations'] += rule_result['violations']\n",
    "        \n",
    "        # Calculate overall validation score\n",
    "        results['validation_score'] = (results['rules_passed'] / results['rules_applied']) * 100 if results['rules_applied'] > 0 else 0\n",
    "        \n",
    "        # Track validation in lineage\n",
    "        event_id = str(uuid.uuid4())\n",
    "        lineage_events.append({\n",
    "            'event_id': event_id,\n",
    "            'event_type': 'VALIDATION',\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'dataset_name': dataset_name,\n",
    "            'validation_summary': {\n",
    "                'total_rows': results['total_rows'],\n",
    "                'rules_applied': results['rules_applied'],\n",
    "                'rules_passed': results['rules_passed'],\n",
    "                'rules_failed': results['rules_failed'],\n",
    "                'validation_score': results['validation_score']\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        pipeline_logs.append(f\"[{datetime.now().strftime('%H:%M:%S')}] VALIDATION: {dataset_name} - {results['validation_score']:.1f}% passed\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def display_validation_summary(self, dataset_name, results):\n",
    "        \"\"\"Display validation summary for a dataset\"\"\"\n",
    "        print(f\"\\\\nüìä {dataset_name} Validation Summary:\")\n",
    "        print(f\"   Total Rows: {results['total_rows']:,}\")\n",
    "        print(f\"   Rules Applied: {results['rules_applied']}\")\n",
    "        print(f\"   Rules Passed: {results['rules_passed']} ‚úÖ\")\n",
    "        print(f\"   Rules Failed: {results['rules_failed']} ‚ùå\")\n",
    "        print(f\"   Total Violations: {results['total_violations']:,}\")\n",
    "        print(f\"   Validation Score: {results['validation_score']:.1f}%\")\n",
    "        \n",
    "        # Show failed rules\n",
    "        if results['rules_failed'] > 0:\n",
    "            print(\"\\\\n‚ùå Failed Rules:\")\n",
    "            for rule_result in results['rule_results']:\n",
    "                if not rule_result['passed']:\n",
    "                    print(f\"   ‚Ä¢ {rule_result['rule_name']}: {rule_result['violations']:,} violations ({rule_result['violation_percentage']:.1f}%)\")\n",
    "    \n",
    "    def create_validation_report(self):\n",
    "        \"\"\"Create comprehensive validation report with visualizations\"\"\"\n",
    "        if not self.validation_results:\n",
    "            return\n",
    "        \n",
    "        # Validation summary chart\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=('Validation Scores by Dataset', 'Rules Pass/Fail Distribution', \n",
    "                          'Violations by Dataset', 'Rule Performance'),\n",
    "            specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}],\n",
    "                   [{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
    "        )\n",
    "        \n",
    "        # Dataset validation scores\n",
    "        datasets = list(self.validation_results.keys())\n",
    "        scores = [self.validation_results[ds]['validation_score'] for ds in datasets]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(x=datasets, y=scores, name=\"Validation Score\", \n",
    "                   marker_color=['green' if s >= 90 else 'orange' if s >= 70 else 'red' for s in scores]),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Overall pass/fail distribution\n",
    "        total_passed = sum(r['rules_passed'] for r in self.validation_results.values())\n",
    "        total_failed = sum(r['rules_failed'] for r in self.validation_results.values())\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Pie(labels=['Passed', 'Failed'], values=[total_passed, total_failed],\n",
    "                   marker_colors=['green', 'red']),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # Violations by dataset\n",
    "        violations = [self.validation_results[ds]['total_violations'] for ds in datasets]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(x=datasets, y=violations, name=\"Total Violations\", marker_color='red'),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Rule performance (top failing rules)\n",
    "        all_rule_results = []\n",
    "        for dataset_results in self.validation_results.values():\n",
    "            all_rule_results.extend(dataset_results['rule_results'])\n",
    "        \n",
    "        failing_rules = [r for r in all_rule_results if not r['passed']]\n",
    "        failing_rules.sort(key=lambda x: x['violations'], reverse=True)\n",
    "        top_failing = failing_rules[:10]  # Top 10 failing rules\n",
    "        \n",
    "        if top_failing:\n",
    "            rule_names = [f\"{r['rule_name']} ({r['dataset']})\" for r in top_failing]\n",
    "            rule_violations = [r['violations'] for r in top_failing]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Bar(x=rule_violations, y=rule_names, orientation='h', \n",
    "                       name=\"Violations\", marker_color='orange'),\n",
    "                row=2, col=2\n",
    "            )\n",
    "        \n",
    "        fig.update_layout(height=800, showlegend=False, title_text=\"Data Validation Report\")\n",
    "        fig.show()\n",
    "        \n",
    "        # Create detailed rule results table\n",
    "        detailed_results = []\n",
    "        for dataset_results in self.validation_results.values():\n",
    "            for rule_result in dataset_results['rule_results']:\n",
    "                detailed_results.append({\n",
    "                    'Dataset': rule_result['dataset'],\n",
    "                    'Rule Name': rule_result['rule_name'],\n",
    "                    'Rule Type': rule_result['rule_type'],\n",
    "                    'Column': rule_result['column'],\n",
    "                    'Status': '‚úÖ Pass' if rule_result['passed'] else '‚ùå Fail',\n",
    "                    'Violations': rule_result['violations'],\n",
    "                    'Violation %': f\"{rule_result['violation_percentage']:.2f}%\"\n",
    "                })\n",
    "        \n",
    "        if detailed_results:\n",
    "            print(\"\\\\nüìã Detailed Rule Results:\")\n",
    "            detailed_df = pd.DataFrame(detailed_results)\n",
    "            display(detailed_df)\n",
    "    \n",
    "    def export_validation_results(self):\n",
    "        \"\"\"Export validation results to files\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Export summary results\n",
    "        summary_data = []\n",
    "        for dataset_name, results in self.validation_results.items():\n",
    "            summary_data.append({\n",
    "                'dataset': dataset_name,\n",
    "                'total_rows': results['total_rows'],\n",
    "                'rules_applied': results['rules_applied'],\n",
    "                'rules_passed': results['rules_passed'],\n",
    "                'rules_failed': results['rules_failed'],\n",
    "                'total_violations': results['total_violations'],\n",
    "                'validation_score': results['validation_score'],\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            })\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_csv(f\"validation_summary_{timestamp}.csv\", index=False)\n",
    "        \n",
    "        # Export detailed results\n",
    "        detailed_data = []\n",
    "        for dataset_results in self.validation_results.values():\n",
    "            for rule_result in dataset_results['rule_results']:\n",
    "                detailed_data.append({\n",
    "                    'dataset': rule_result['dataset'],\n",
    "                    'rule_name': rule_result['rule_name'],\n",
    "                    'rule_type': rule_result['rule_type'],\n",
    "                    'column': rule_result['column'],\n",
    "                    'passed': rule_result['passed'],\n",
    "                    'violations': rule_result['violations'],\n",
    "                    'violation_percentage': rule_result['violation_percentage'],\n",
    "                    'error': rule_result.get('error', ''),\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                })\n",
    "        \n",
    "        detailed_df = pd.DataFrame(detailed_data)\n",
    "        detailed_df.to_csv(f\"validation_detailed_{timestamp}.csv\", index=False)\n",
    "\n",
    "# Create validation engine and display widget\n",
    "validation_engine = ValidationEngine(spark, rule_manager, upload_manager)\n",
    "validation_widget = validation_engine.create_validation_widget()\n",
    "display(validation_widget)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
